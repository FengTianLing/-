##### 进程和线程的区别

进程是资源分配的最小单位，线程是CPU调度的最小单位。

+ 所有与进程相关的资源，都被记录在PCB中
+ 进程是抢占处理机的调度单位；线程属于某个进程，共享其资源
+ 线程只有堆栈寄存器，程序计数器，和线程控制表TCB组成 

总结：

+ 线程不能看作独立应用，而进程可用看作独立应用
+ 进程有独立的地址空间，相互不影响，线程只是进程的不同执行的路径
+ 线程有自己的堆栈，线程没有独立的地址空间，多进程的程序比多线程程序要健壮  
+ 进程的切换比线程的切换开销大



##### Javaj进程和线程的关系

+ Java对操作系统提供的功能进行了封装，包括进程和线程
+ 运行一个程序会产生一个Java进程，进程包含至少一个线程
+ 每个Java进程对应一个JVM实例，多个线程共享JVM里的堆 
+ Java采用单线程编程模型，程序会自动创建主线程
+ 主线程可以创建子线程，原则上后于子线程完成执行



##### Thead中的start和run方法的区别

+ 调用start方法回创建一个子线程并启动
+ run方法只是Thread类的一个普通方法调用

##### Thread和Runnable是什么关系

+ Thread实现了Runnable接口的类，使Runnable得run支持多线程特性
+ 因类的单一继承原则，推荐多使用Runnable接口



##### 如何给run()传参

+ 构造函数
+ 成员变量
+ 回调函数传参



##### 如何处理线程的返回值

+ 主线程等待法。实现起来比较简单，  缺点是需要自己实现等待逻辑，当需要等待的变量一多，代码就回变得臃肿。关键的是需要循坏等待多久不确定的，没法做到精准控制。
+ 使用Thread类的join()阻塞当前线程以等待子线程处理完毕。比主线程循环等待更精准控制。更简单实现。缺点是粒度不够细，比如某段逻辑执行到一半的时候，暂停执行另外的线程
+ 通过Callbalie接口实现：通过FutureTask 或线程池获取





##### 线程的状态(六个)

**NEW**：线程创建后尚未启动的线程的状态

**RUNNABLE**：包含Running和Ready

**WAITING**：无限期等待，不会被分配CPU执行时间，需要显式的被唤醒。没有设置Timeout参数的Object.wait()方法。没有设置Timeout参数的Thread.join()方法。LockSupport.park()方法

**TIMED_WAITING**：限期等待，在一定的时间后由系统自动唤醒。设置Timeout参数的Object.wait()方法；设置Timeout参数的Thread.join()方法；LockSupport.parkNanos()方法；LockSupport.parkUntil()方法

**BLOCKED**：等待获取排他锁

**TERMINATED**：结束，已终止线程的状态，线程已经结束执行。



##### Sleep和wait的区别

+ Sleep是Thread类的方法，wait是Object的方法
+ sleep()方法可以在任何地方使用，wait()方法只能在synchronized方法或synchronized块使用
+ Thread.sleep()只会让出CPU，不会导致锁行为的改变
+ Object.wait()不仅让出CPU，还会释放已经占有的同步锁



##### notify和notifyAll的区别

+ notifyAll会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会
+ notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会



两个概念

对于java虚拟机中运行程序的每个对象，都有两个池，锁池和等待池。这两个池又与Object类的wait(),notify(),notifyAll()以及synchronized相关。

**锁池EntryList**：假设线程A已经拥有了某个对象(不是类)的锁，而其它线程B,C想要调用这个对象的某个synchronized方法（或者块），由于B,C线程在进入对象的synchronized方法（或者块）之前，必须先获得该对象锁的拥有权，而恰巧该对象的锁目前正在A占用，此时BC线程就会被阻塞，进入一个地方等待锁的释放，这个地方便是该对象的锁池。

**等待池WaitSet**：假设线程A调用了某个对象的wait()方法，线程A就会释放掉该对象的锁，同时线程A就进入了该对象的等待池中，进入到等待池中的线程不会去竞争该对象的锁。





##### yield函数

当调用Thread.yield()函数时，会给线程调度器一个当前线程愿意养出CPU使用的暗示，但是线程调度器可能会忽略掉这个暗示。

通俗讲就是当前线程愿意让出CPU使用权，让其他线程可以获取这个CPU的使用权，但是这取决于调度器。



##### interrup函数

如何中断线程

**已经被抛弃的方法**

+ 通过调用top()方法停止线程：stop方法可以由一个线程去停止另外一个线程的。这种方法太过暴力，而且是不安全的。比如线程A调用线程B的stop方法，这种突然间的停止会导致线程B的清理工作无法完成。还有就是执行stop方法后线程B会马上释放锁，由可能会引发数据不 同步的问题。 所有被抛弃使用了
+ 通过调用suspend()和resume()方法。

目前使用的方法

+ interrup：通知线程应该中断了。

作用其实不是中断线程，和yield一样是通知线程应该中断了。到底是否被中断，应该由被通知的线程自己去处理。

1.当一个线程调用interrup方法时，如果线程处于被阻塞状态（sleep,wait,join），那么线程将立即退出被阻塞的状态，并且抛出InterruptedException异常

2.如果线程处于正常活动状态，那么会将该线程的中断标记设置为true。被设置中断标记的线程将继续正常运行，不受影响。

以上知道，interrup并不能真正的中断线程，需要被调用的线程自己配合才行。如果一个线程有被中断的需求

1.在正常运行任务时，经常检查本线程的中断标志位，如果被设置了中断标志就自行停止线程

##### 线程的生命周期

![image-20200904005108695](md-images/07-多线程与并发/image-20200904005108695.png)

# synchronized

**线程安全问题的主要诱因**

1. 存在共享数据（也称为临界资源）
2. 存在多条线程共同潮州这些共享数据

**解决问题的根本方法**

保证同一时刻有且只有一个线程在操作共享数据，其他线程必须等待该线程处理完数据后在对共享数据进行操作

**互斥锁特性**

1.互斥性：即在同一个时间只允许一个线程持有某个对象锁，通过这种特性来实现多线程的协调机制，这样在同一时间只有一个线程对需要的同步的代码块（符合操作）进行访问。互斥性也称为操作的原子性。

2.可见性：必须确保在锁被释放之前，对共享变量的所作的修改，对于随后获得该锁的另外一个线程是可见的。即在获得锁时应获得最新共享变量的值。否则另一个线程可能在本地缓存的某个副本上继续操作，从而引起不一致。



#### synchronized获取锁的分类

**获取对象锁**

1. 同步代码块 synchronized(this)。synchronized(实例对象)。锁是小括号()中的实例对象

2. 同步非静态方法。就是被synchronized修饰的非静态方法。锁是当前对象的实例对象



**获取类锁**

1. 同步代码块 synchronized(类.class) ，锁是小括号()中的类对象（Class对象）
2. 同步静态方法。就是被synchronized 修饰的静态方法。锁是当前对象的类对象(Class对象)。

**总结**

1. 有线程访问对象的同步代码块时候，另外的线程可以访问该对象的非同步代码块
2. 若锁住的是同一个对象，一个线程在访问对象的同步代码块时候，另一个线程访问对象的同步代码块会被阻塞
3. 锁锁住的是同一个对象，一个线程在访问对象的同步方法时，另一个线程访问对象的同步方法会被阻塞
4. 若锁住的是同一个对象，一个线程在访问对象的同步代码块时，另一个线程访问对象的同步方法会被阻塞，反之亦然
5. 同一个类不同对象的对象锁互不干扰
6. 类锁由于也是一个特殊的对象所，因此表现和上诉1，2，3，4一致，由于一个类只有一把对象锁，所以同一个类的不同对象使用锁都会是同步的
7. 类锁和对象锁互不干扰



#### synchronized的底层原理

**Java对象头**：

![image-20200904215051331](md-images/07-多线程与并发/image-20200904215051331.png)

![image-20200904215514369](md-images/07-多线程与并发/image-20200904215514369.png)



对象在内存中的布局。分对象头，实例数据，对其填充。

一般而言，synchronized使用的锁对象， 是存储在Java对象头里面的，其主要结构是 Mark Word 和 Class metadata Address 组成。其中 Class matedata Address 是对象指向它类元数据的指针，JVM通过这个指针来确定这个对象是哪个类的实例。而mark word则用于存储对象自身的运行时数据的，是实现轻量级锁和偏向锁的关键。

由于对象头的信息，是与对象自身定义的数据没什么关系额外存储成本，因此考虑到JVM的空间效率，mark word被设计称为一个非固定的数据结构。以便存储更多有效的数据。 它会根据对象本身的状态，复用自己的存储空间。

**Monitor**：每个Java对象天生自带了一把看不见的锁。它就是Monitor锁，也叫管程或者监视器锁。可以把它理解为一个同步工具。也可以描述为一种同步机制。上图的重量级锁，即synchronized对象锁，其中指针指向的是monitor对象的启始地址，每个对象都存在这一个monitor与之关联。对象与monitor的关系，有存在多种实现方式，如果monitor可以和对象一起创建销毁。或当线程试图获取对象锁时，自动生成。但当一个Monitor被某个线程持有后，它变处于锁定状态。在jvm中，monitor是由ObjectMonitor实现的。

![image-20200904221439613](md-images/07-多线程与并发/image-20200904221439613.png)



**为什么会对Synchronized嗤之以鼻**

1. 早期版本版中，synchronized属于重量级锁，依赖Mutex Lock实现
2. 线程直线的切换需要从用户态转换到核心态，开销较大
3. JDK6以后，synchronized性能得到了很大的提升
   + Adptive Spinning 自旋
   + Lock Eliminate 锁消除
   + Lock Coarsening 锁粗化
   + Lightweight Locking 轻量级锁
   + Biased Locking 偏向锁



**自旋锁**: 很多情况下，共享数据的锁定状态只会持很短的续时间，为了这点时间去挂起何恢复阻塞线程并不值得。在如今多处理器的情况下，完全可以让另一个没有获取到锁的线程，在门外等待一会，但不放弃CPU的执行时间， 通过让线程执行忙循环，等待锁的释放。缺点就是，若锁被其他线程长时间占用，会带来许多性能上的开销。因为线程自旋时是不会让出CPU的执行时间的，时间太长会白白消耗掉CPU资源。因此自旋等待的时间必须要有一定的限度，如果自旋超过了限定的尝试次数，就应该使用传统的方式挂起线程。可以通过preBlockSpin更改。

**自适应自选锁**

1. 自旋的次数不在固定
2. 由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定



**锁消除**

虚拟机另外一种锁优化，这种优化更彻底。Java虚拟机在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，消除没有必要的锁。

**锁粗化**

另外一个极端。在加同步锁的时候，尽可能将同步块的作用范围，限制到尽量笑的范围，即指在共享数据的实际作用域中，才进行同步，这样是为了使得需要同步的操作数量尽可能变小。在存在锁同步竞争中，也可以使得等待锁的线程尽早的拿到锁。 如果存在一连串系列操作，都对同一个对象进行反复加锁和解锁，甚至加锁操作出现在循环体中的，即使没有线程竞争，频繁的进行互斥同步锁操作，也回导致不必要的性能浪费。通过扩大加锁的范文，避免反复加锁和解锁。

#### synchronized的4中状态

无锁，偏向锁，轻量级锁，重量级锁。

它会随着竞争情况逐渐升级。有些认为不会进行锁降级，但其实是会发生的，当JVM进入安全点的时候，是否有限制的monitor，然后视图进行降级。锁的膨胀方向从左到右。

**偏向锁**：

大多数情况下，锁不存在多线程竞争，总是由同一线程多次获得，因此为了减少同一线程获取锁的代价，引入偏向锁。核心思想。如果一个线程获得了锁，那么锁就进入偏向模式，此时mark work的结构也变为偏向锁结构，当该线程再次请求锁时，无需再做任何同步操作。即获取锁的过程只要检查Mark word的锁标记位为偏向锁以及当前线程ID的等于mark word的ThreadID即可，这样就省去了大量有关的锁申请的操作。但是对于锁竞争比较激烈的场合，偏向锁就失效了，会升级为轻量级锁。

**轻量级锁**

是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁竞争的时候，偏向锁就会升级为轻量级锁。适应场景是线程交替执行的同步块。若存在同一个时间多线程访问同一个锁的情况，就会导致轻量级锁膨胀为重量级锁。



**锁的内存语义**

当线程释放锁时，JAVA内存模型会把该线程对应的本地内存的共享变量刷新到主内存中

当线程获取锁时，JAVA内存模型会把该线程的对应的本地内存置为无效，从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。



![image-20200905203522668](md-images/07-多线程与并发/image-20200905203522668.png)



#### synchronize和ReentrantLock的区别

**ReentrantLock**

在JAVA5以前，synchronized是仅有的同步手段，从JAVA5开始以后，便提供ReentrantLock，即再入锁的实现。语义和synchronize基本相同。通过代码直接调用lock方法去获取锁。编写更加灵活。

位于java.utl.concurrent.locks包下，它提供了很多使用的方法。java.utl.concurrent这个包下，即业内文明的juc包，里面比较有名的工具类，几乎都是基于daoli大神写的AQS抽象类框架延申出来的引用。

此外，ReentrantLock，和ConutDowLatch，FutrureTask，Semaphore一样是基于AQS实现。AQS即 AbstractQueueSynchronizer抽象类，队列同步器；它JAVA并发用来构建锁或其他同步组件的基础框架，是juc包的核心。一般使用AQS的主要方式是继承。利用AQS为我们构建同步结构提供了范本。利用它实现一个同步结构，至少要实现两个基本类型的方法，分别是acquire(获取资源独占权)和release(释放对某个资源的独占)。

ReentrantLock能够实现比Synchronized更细粒度的控制，比如控制fairness 即公平性。

编码中需要注意，调用lock()之后，必须要明确调用unlock()释放锁 。不然当前线程就一直持有该锁不会释放。 

性能未必比synchronized高，synchronized经过后续版本的改进，再低竞争场景中，表现可能会优于ReentrantLock。并且也是可重入的，即当一个线程试图获取一个它已经获取的锁时，这个获取动作就会成功。

ReentrantLock公平性设置，构造方法传入true,就是公平性的。所谓公平，是倾向于将锁赋予等待时间最久的线程。公平性是减少线程饥饿的一个办法，线程饥饿是线程长期等待锁，确始终无法获取锁的情况。公平锁，即获取锁的顺序按先后调用lock方法的顺序(慎用)。非公平锁，抢占的顺序不一定，看运气，synchronized是非公平锁。公平性未必好，额外的开销和吞吐量下降。

**ReentrantLock对象化**

ReentrantLock因为可以想普通对象那样使用，可以利用它来提提供各种便宜的方法，进行精细的同步操作。甚至可以实现synchronized难以表达的案例。比如 

1.判断是否有线程；或者某个特定的线程，在排队等待获取锁。

2.带超时的获取锁的尝试。

3.可以感知到有没有成功获取到锁。

**wait notify notifyAll 方法对象化**

如果说ReentrantLock是把synchronize转变成了可空对象化，是不是也可以把wait notify notifyAll 转换为相应的对象，即负责的同步操作，转变成直观可控制的对象行为。

位于 java.utl.concurrent.locks.Condition做到了这一点。最为典型的应用场景就是ArrayBlockingQueue

**ArrayBlockingQueue**

ArrayBlockingQueue是数组实现的，线程安全的，有界的阻塞队列。线程安全是指它内部通过互斥锁保护竞争资源，它的互斥锁就是通过ReentrantLoc实现的。有界指的是它内部的数组是由界限的。阻塞队列是指多线程访问竞争资源时，当线程已经被某线程获取时，其他要获取该资源的线程需要阻塞等待。ArrayBlockingQueue饥饿Condition是组合的关系。

##### **总结**

+ synchronized是关键字，ReentrantLock是类
+ ReentrantLock可以获取锁的等待时间设置避免死锁
+ ReentrantLock可以获取各种锁的信息
+ ReentrantLock可以灵活实现多路通知
+ 机制，synchronized操作是对象头中Mark work加锁。lock方法调用Unsafe类的park()方法加锁







# JAVA内存模型JMM

Java内存模型，即Java Memory Model,简称JMM。本身是一种抽象的概念，并不真实存在，它描述的是一组规则或规范。通过这组规范，定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式。

![image-20200906160935050](md-images/07-多线程与并发/image-20200906160935050.png)

由于运行程序的实体是线程，而每个线程创建时，JVM都会为该线程创建一个工作内存，有些地方称为栈空间。用来存储线程私有的数据，而JAVA内存模型种，规定所有变量都存储在主内存中，主内存是共享内存区域，所有线程都可以访问。但线程对变量的操作，必须在工作内存中进行。首先将变量从主内存拷贝到自己的工作内存中，对变量进行操作，  完成后再将变量写回主内存中，不能直接操作主内存中的变量。工作内存中存储着主内存的副本拷贝。  线程间的传值必须通过主内存来完成。



**JMM中的主内存**

注意存储的是JAVA实例对象，所有线程创建的实例都存放再主内存中。包括成员变量，类信息，常量，静态变量等。由于是数据共享区域，多线程并发操作会引发线程安全问题。



**JMM的工作内存**

主要存储当前方法的所有本地变量信息，本地变量是对其他线程不可见。包括了字节码行号自食其，Native方法信息。由于工作内存是每个线程的私有区域，线程间无法相互访问工作内存，因此存储在工作内存的数据，不存在线程安全问题。



**JMM与java内存区域划分是不同概念层次**

JMM描述的是一组规则，通过这组规则定义了程序的共享数据区域和私有数据区域各个变量的访问方式，围绕原子性，有序性，可见性展开的。

它们唯一的相似点 存在共享区域和私有区域，JMM的主内存属于共享数据区域，工作内存属于私有数据区域。



**主内存与工作内存数据存储类型以及操作方式**

+ 方法里面的基本类型本地变量将直接存储在工作内存的栈帧结构中。
+ 如果是是引用变量，引用存储在工作内存中，实例存储在主内存中。
+ 实例里的成员变量、static变量、类信息均会被存储在主内存中。
+ 在主内存中的实例对象，可以被多线程共享，如果两个线程同时调用了同一个对象的同一个方法，那么两条线程会将操作的数据拷贝一份到自己的工作内存中，操作完成后刷新回主内存

## **JMM如何解决可见性问题**

![image-20200906163313106](md-images/07-多线程与并发/image-20200906163313106.png)

把数据从内存加载到缓存寄存器，运算结束后写回主内存。

当线程共享变量的时候，情况就变得复杂了，如果处理器对某个变量进行了修改，可能指是体现该内核的缓存里，这是个本地状态，而运行在其他内核上的线程，可能加载的旧状态，这很可能导致一致性的问题。从理论上说，多线程共享引入了复杂的数据依赖性。不管编译器，处理器怎么做重排序，都必须尊重数据依赖性的要求，否则就打破了数据的正确性，这就是JMM所要解决的问题。



**指令重排序需要满足的条件**

 在执行程序的时候，为了提高性能，处理器和编译器常常回对指令进行重排序，但是不能随意重排序 ，需要满足以下 

+ 在单线程环境下不能改变程序的运行结果
+ 存在数据依赖关系不允许重排序

以上两点可以归纳为 无法通过happens-before原则推到出来的，才能进行指令的重排序。JMM内部的实现，通常是依赖于所谓的内存屏障，通过禁止某些重排序的方式，提供内存可见性保证，也就是实现了各种happens-before的规则

A操作的结果需要对B操作可见，则A与B存在happens-before的关系。

```java
i=1; //线程A执行
j=i  //线程B执行
```

happens-before原则非常重要，它是判断数据是否存在竞争，线程是否安全的主要依据。依靠这个原则，就能解决在并发环境下，两个操作之间存在冲突的问题。

happens-before八大原则：

![image-20200906164927603](md-images/07-多线程与并发/image-20200906164927603.png)

**happens-before概念**

如果两个操作不满足上述任意一个happens-before规则，那么这两个操作就没由顺序的保证，JVM可以对这两个操作进行重排序；

如果操作A happens-before操作B ，那么操作A在内存上所做的操作对操作B都是可见的。



### Volatile

volatile在并发编程中很常见，但也很容易被滥用。volatile是JAVA虚拟机轻量级的同步机制。volatile关键由如下两个作用

1.保证volatitle修饰的共享变量对所有线程总是可见的。即当一个线程修改了被volatile修饰的共享变量的值，其他线程能立即感知到变动

2.禁止指令的重排序优化



**volatitle可见性**

我们必须意识到，被volatile修饰的变量，多所有线程总是立即可见的，对volatile的所有写操作，总是能立即反应到其他的线程中。但是对volatile运算操作在多线程环境中，并不保证安全性。

```java
public class VolatileVisibility{
    public static volatile int value = 0;
    
    public static void increase(){  //多线程必须+synchronized修饰
        value++
    }
}
```

以上代码，如果多条线程同时操作increase方法，  就回出现线程安全问题，毕竟value++并不具备原子性，这个操作分为两步来执行，先读在写，如一个线程读取到value值，还没来得及写操作，另外的线程也读到了，就引发了线程安全问题。所有以上代码必须使用synchronized修饰，以便保证线程安全。需要补充和注意的是，synchronized关键字解决的是执行控制的问题的，它会阻止其他线程获取当前对象的监控锁，这样就使得当前对象中的被synchornized保护的代码块无法被其他线程访问，也就无法并发执行。synchronized还会创建内存屏障，内存屏障指令保证了所有CPU结果，都会直接刷到主内存中。从而保证了内存的可见性。就可以省去了volatile修饰变量



另外一种场景达到线程安全目的

```java
public class volatileSafe{
    
    volatile boolean shutdown;
    
    public void close(){
        shutdown = true;
    }
    
    public void doWork(){
        while(!shutdown){
            System.out.println("safe...")
        }
    }
    
}
```



以上代码，由于对boolean属于原子性操作，所以可以使用volatile修饰



**volatile变量如何实现对其他线程立即可见**

当写一个volatile变量时，JMM会把该线程的对应的工作内存中的共享变量值刷新到主内存中

当读一个volatile变量是，JMM会把该线程对应的工作内存置为无效。那么该线程将只能从主内存中重新读取共享变量。



**volatile如何禁止重拍优化**

内存屏障（Memory Barrier）：CPU指令

1. 保证特定操作的执行顺序
2. 保证某些变量内存可见性

通过插入内存屏障指令，禁止在内存屏障前后的指令执行重排序优化

强制刷出各种CPU缓存数据，因此任何CPU上的线程都能出去到这些数据的最新版本。



**volatile和synchronized的区别**

1. volatile本质是告诉JVM当前变量在工作内存中的值是不确定的，需要从内存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞知道该线程完成变量的操作为止
2. volatile只能使用在变量级别；synchronized则可以使用在变量，方法和类级别上
3. volatile只能实现变量的修改可见性，不保证原子性；而synchronized则可以保证变量的修改的可见性和原子性
4. volatile不会造成线程阻塞，synchronized可能会造成线程阻塞都
5. volatile标记的变量不会被编译器优化，synchronized标记的标签可以被编译器优化。





# CAS

Compare and Swap 即比较且交换

像synchronized这种独占锁，属于悲观锁。悲观锁始终认为会发生并发冲突，因此会屏蔽一切可能违反数据完整性的操作。

乐观锁，他始终认为不会发生并发冲突，因此指在提交操作时，检查是否违反数据完整性，如果提交失败，则会进行重试。乐观锁最常见的就是CAS。



CAS是一种高效实现线程安全的方法。它支持原子更新操作，适用于计数器，序列发生器等场合。序列发生器，就是给变量自增的工具。CAS和传统的加锁方式，CAS是一种乐观方式的加锁行为，号称lock-free。这里的无锁只是上层我们感知的无所，底层仍然是有加行为的。CAS操作失败时有开发者决定是继续尝试，还是执行别的操作。

**CAS思想**

包含三各操作数 — 内存位置 V  ，预期原值 A  和新值B。 

执行CAS操作的时候，将内存位置的值V，与预期原值进行比较，如果相匹配，那么处理器会将该位置的值，更新为新值B。否则处理器不会做任何操作。这里内存位置的值，就是主内存的值。

举例：当一个线程需要修改共享变量的值，会先取出共享变量的值赋值给A，然后基于A的基础进行计算，得到新值B，执行完毕需要更新共享变量的值的时候，就可以调用CAS方法去更新共享变量的值了。

 

CAS多数情况下对开发来说是透明的

+ J.U.C的atomic包提供了常用的原子性数据类型以及引用、数组等相关的原子类型和更新操作工具，是很多线程安全程序的首选
+ UnSafe类索然提供了CAS服务，但因能够任意内存地址读写而又隐患。
+ Java9以后，可以使用Variable Handle API来代替UnSafe

大多数情况下，开发者并不需要直接利用CAS代码，去实现线程安全问题，更多的是通过并发包，间接享受到lock-free机制，在扩展性上的好处。

缺点:

+ 若循环时间长，开销很大
+ 只能保证一个共享变量的原子操作
+ ABA问题。如果内存地址V，初次读取的值是A，并且在准备赋值的时候，它看到的值是别的线程是从B又改回了A，CAS操作就回误认为没有改变过。解决 这个问题，JUC提供了一个带有标记的原子引用类，AtomicStampedReferece，它可以通过变量值的版本老保证正确性。





# 线程池

不使用线程池，可能回出现程序在创建和销毁线程时间，和消耗的系统资源，要比实际处理用户请求的时间和资源更多。

**Executros（5中线程池创建配置）**

![image-20200906211411037](md-images/07-多线程与并发/image-20200906211411037.png)



Q：为什么要使用线程池

A：

+ 降低资源消耗，即通过重复利用已创建的线程来降低线程创建和销毁造成的消耗。
+ 提高线程的可管理型。线程是稀缺资源，如果无限制的创建，不仅会消耗资源，还会降低系统的稳定性。使用线程池可以进行同一的分配和监控



J.U.C的三个Executor接口

+ Executor：运行新任务的简单接口，讲任务提交和任务执行细节解耦。
+ ExecutrorServie:具备管理执行器和任务生命周期的方法，提交任务机制更完善



ThreadPoolExecutor的构造函数

+ corePoolSize:核心的线程数量
+ maxnimumPoolSize:线程不够用时能够创建的最大线程数
+ workQueue:任务等待队列
+ keepAliveTime:抢占式顺序不一定，看运气
+ threadFactory:创建新线程，Executors.DefaultThreadFactory()

handler:线程池的饱和策略:如果阻塞队列满了，并且没有空闲的线程，如果继续提交任务，就要采取策略处理该任务

+ AbortPolicy:直接抛出异常，这是默认的策略
+ CallerRunsPolicy: 用调用者所在的线程来执行任务
+ DiscardOldestPolicy:丢弃阻塞队列中靠最前的任务，并执行当前任务
+ DiscardPolicy:直接丢弃任务
+ 实现RejectedExecutionHandeler接口自定义Handler

![image-20200906214935742](md-images/07-多线程与并发/image-20200906214935742.png)

![image-20200906215053149](md-images/07-多线程与并发/image-20200906215053149.png)

**线程池的状态**

+ Running:能接收新提交的任务，并且也能处理阻塞队列中的任务
+  Shutdown:不在接收新提交的任务，但可以继续处理阻塞队列中已经保存的任务
+  Stop:不在接收新提交的任务，也不处理阻塞队列里的任务
+ Tidying:所有的任务都已经终止
+ Terminated:Terminated()方法执行完后进入状态，什么也不做，作为一个标识

![image-20200906215818390](md-images/07-多线程与并发/image-20200906215818390.png)

工作线程的生命周期

![image-20200906215921572](md-images/07-多线程与并发/image-20200906215921572.png)

Q：线程池的大小如何选定

A：
CPU密集型:即计算类型的任务，则 线程数= 按照CPU核心或CPU核心数+1

I/O密集型：即较多等待的任务，则 线程数 = CPU核心数*（1+平均等待时间/平均工作时间）

